<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Convergent Learning: Do different neural networks learn the same representations? | FE 2015 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Convergent Learning: Do different neural networks learn the same representations?">

  <meta name="citation_author" content="Li, Yixuan">

  <meta name="citation_author" content="Yosinski, Jason">

  <meta name="citation_author" content="Clune, Jeff">

  <meta name="citation_author" content="Lipson, Hod">

  <meta name="citation_author" content="Hopcroft, John">

<meta name="citation_publication_date" content="2015">
<meta name="citation_conference_title" content="Proceedings of The 1st International Workshop on “Feature Extraction: Modern Questions and Challenges”, NIPS">
<meta name="citation_firstpage" content="196">
<meta name="citation_lastpage" content="212">
<meta name="citation_pdf_url" content="li15convergent.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Convergent Learning: Do different neural networks learn the same representations?</h1>

	<div id="authors">
	
		Yixuan Li,
	
		Jason Yosinski,
	
		Jeff Clune,
	
		Hod Lipson,
	
		John Hopcroft
	<br />
	</div>
	<div id="info">
		Proceedings of The 1st International Workshop on “Feature Extraction: Modern Questions and Challenges”, NIPS,
		pp. 196–212, 2015
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		Recent successes in training large, deep neural networks (DNNs) have prompted active investigation into the underlying representations learned on their intermediate layers. Such research is difficult because it requires making sense of non-linear computations performed by millions of learned parameters. However, despite the difficulty, such research is valuable because it increases our ability to understand current models and training algorithms and thus create improved versions of them. We argue for the value of investigating whether neural networks exhibit what we call convergent learning, which is when separately trained DNNs learn features that converge to span similar spaces. We further begin research into this question by introducing two techniques to approximately align neurons from two networks: a bipartite matching approach that makes one-to-one assignments between neurons and a spectral clustering approach that finds many-to-many mappings. Our initial approach to answering this question reveals many interesting, previously unknown properties of neural networks, and we argue that future research into the question of convergent learning will yield many more. The insights described here include (1) that some features are learned reliably in multiple networks, yet other features are not consistently learned; and (2) that units learn to span low-dimensional subspaces and, while these subspaces are common to multiple networks, the specific basis vectors learned are not; (3) that the average activation values of neurons vary considerably within a network, yet the mean activation values across different networks converge to an almost identical distribution.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="li15convergent.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
