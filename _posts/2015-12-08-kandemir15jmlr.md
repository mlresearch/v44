---
title: 'The Deep Feed-Forward Gaussian Process: An Effective Generalization to Covariance
  Priors'
abstract: We explore ways of applying a prior on the covariance matrix of a Gaussian
  Process (GP) in order to increase its expressive power. We show that two well-known
  covariance priors, Wishart Process and Inverse Wishart Process, boil down to a two-layer
  feed-forward net- work of GPs with a particular kernel function on the neuron at
  the output layer. Both of these models perform supervised manifold learning and
  target prediction jointly. Also, the resultant kernel functions of both of these
  priors lead to feature maps of finite dimen- sionality. Motivated by this fact,
  we promote replacing these kernels with the Radial Basis Function (RBF), which gives
  an infinite dimensional feature map, enhancing the model flex- ibility. We demonstrate
  on one benchmark task and two challenging medical image analysis tasks that our
  GP network with RBF kernel largely outperforms the earlier two covariance priors.
  We show also that it straightforwardly allows non-linear combination of different
  data views, leading to state-of-the-art multiple kernel learning only as a by-product.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: kandemir15jmlr
month: 0
firstpage: 145
lastpage: 159
page: 145-159
sections: 
author:
- given: Melih
  family: Kandemir
- given: Fred A.
  family: Hamprecht
date: 2015-12-08
address: Montreal, Canada
publisher: PMLR
container-title: 'Proceedings of the 1st International Workshop on Feature Extraction:
  Modern Questions and Challenges at NIPS 2015'
volume: '44'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 12
  - 8
pdf: http://proceedings.mlr.press/v44/kandemir15jmlr.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
