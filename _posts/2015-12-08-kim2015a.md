---
title: Deep Clustered Convolutional Kernels
abstract: Deep neural networks have recently achieved state of the art performance
  thanks to new training algorithms for rapid parameter estimation and new regularizations
  to reduce over- fitting. However, in practice the network architecture has to be
  manually set by domain experts, generally by a costly trial and error procedure,
  which often accounts for a large portion of the final system performance. We view
  this as a limitation and propose a novel training algorithm that automatically optimizes
  network architecture, by progressively increasing model complexity and then eliminating
  model redundancy by selectively removing parameters at training time. For convolutional
  neural networks, our method relies on iterative split/merge clustering of convolutional
  kernels interleaved by stochastic gradient descent. We present a training algorithm
  and experimental results on three different vision tasks, showing improved performance
  compared to similarly sized hand-crafted architec- tures.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: kim2015a
month: 0
tex_title: Deep Clustered Convolutional Kernels
firstpage: 160
lastpage: 172
page: 160-172
sections: 
author:
- given: Minyoung
  family: Kim
- given: Luca
  family: Rigazio
date: 2015-12-08
address: Montreal, Canada
publisher: PMLR
container-title: 'Proceedings of the 1st International Workshop on Feature Extraction:
  Modern Questions and Challenges at NIPS 2015'
volume: '44'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 12
  - 8
pdf: http://proceedings.mlr.press/v44/kim2015a.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
